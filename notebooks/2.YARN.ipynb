{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/0c/9c5d5dd254e9e7a32d34777cc6fd33cbeb174744061458b88470aecbd1d6/python_dotenv-0.18.0-py2.py3-none-any.whl\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.18.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'HOSTNAME': 'hadoop',\n",
       " 'OLDPWD': '/',\n",
       " 'PWD': '/opt',\n",
       " 'HOME': '/home/hadoop',\n",
       " 'SHELL': '/bin/bash',\n",
       " 'SHLVL': '1',\n",
       " 'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/hadoop/bin:/opt/hadoop/sbin',\n",
       " '_': '/usr/bin/nohup',\n",
       " 'JPY_PARENT_PID': '1660',\n",
       " 'TERM': 'xterm-color',\n",
       " 'CLICOLOR': '1',\n",
       " 'PAGER': 'cat',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
       " 'JAVA_HOME': '/usr/lib/jvm/java-1.8.0-openjdk-amd64',\n",
       " 'PDSH_RCMD_TYPE': 'ssh',\n",
       " 'HADOOP_HOME': '/opt/hadoop',\n",
       " 'HADOOP_COMMON_HOME': '/opt/hadoop',\n",
       " 'HADOOP_CONF_DIR': '/opt/hadoop/etc/hadoop',\n",
       " 'HADOOP_HDFS_HOME': '/opt/hadoop',\n",
       " 'HADOOP_MAPRED_HOME': '/opt/hadoop',\n",
       " 'HADOOP_YARN_HOME': '/opt/hadoop'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source /opt/envvars.sh\n",
    "\n",
    "!pip3 install python-dotenv\n",
    "%load_ext dotenv\n",
    "%dotenv -o /opt/envvars.sh\n",
    "%env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YARN - Web interface\n",
    "\n",
    "- Master node\n",
    "    - Resource Manager: http://localhost:8088\n",
    "    - Timeline Service: http://localhost:8188\n",
    "- Worker node\n",
    "    - hadoop1\n",
    "        - NodeManager: http://localhost:8042\n",
    "    - hadoop2\n",
    "        - NodeManager: http://localhost:8043\n",
    "    - hadoop3\n",
    "        - NodeManager: http://localhost:8044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop MapReduce Examples\n",
    "\n",
    "```\n",
    "$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar\n",
    "```\n",
    "\n",
    "- aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.\n",
    "- aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.\n",
    "- bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.\n",
    "- dbcount: An example job that count the pageview counts from a database.\n",
    "- distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.\n",
    "- grep: A map/reduce program that counts the matches of a regex in the input.\n",
    "- join: A job that effects a join over sorted, equally partitioned datasets\n",
    "- multifilewc: A job that counts words from several files.\n",
    "- pentomino: A map/reduce tile laying program to find solutions to pentomino problems.\n",
    "- pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.\n",
    "- randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.\n",
    "- randomwriter: A map/reduce program that writes 10GB of random data per node.\n",
    "- secondarysort: An example defining a secondary sort to the reduce.\n",
    "- sort: A map/reduce program that sorts the data written by the random writer.\n",
    "- sudoku: A sudoku solver.\n",
    "- teragen: Generate data for the terasort\n",
    "- terasort: Run the terasort\n",
    "- teravalidate: Checking results of terasort\n",
    "- wordcount: A map/reduce program that counts the words in the input files.\n",
    "- wordmean: A map/reduce program that counts the average length of the words in the input files.\n",
    "- wordmedian: A map/reduce program that counts the median length of the words in the input files.\n",
    "- wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 3 maps.\n",
      "Job started: Sat Jun 26 21:32:23 GMT 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-26 21:32:23,313 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:32:23,466 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n",
      "2021-06-26 21:32:23,927 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:32:23,928 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n",
      "org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://hadoop:9000/user/hadoop/randomtext already exists\n",
      "\tat org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:164)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)\n",
      "\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1565)\n",
      "\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1562)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)\n",
      "\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1562)\n",
      "\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1583)\n",
      "\tat org.apache.hadoop.examples.RandomTextWriter.run(RandomTextWriter.java:237)\n",
      "\tat org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)\n",
      "\tat org.apache.hadoop.examples.RandomTextWriter.main(RandomTextWriter.java:248)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n",
      "\tat org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n",
      "\tat org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:323)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:236)\n",
      "2021-06-26 21:32:25,600 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:32:25,748 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n",
      "2021-06-26 21:32:25,945 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0002\n",
      "2021-06-26 21:32:26,228 INFO input.FileInputFormat: Total input files to process : 3\n",
      "2021-06-26 21:32:26,375 INFO mapreduce.JobSubmitter: number of splits:6\n",
      "2021-06-26 21:32:26,514 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1624742957627_0002\n",
      "2021-06-26 21:32:26,516 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2021-06-26 21:32:26,658 INFO conf.Configuration: resource-types.xml not found\n",
      "2021-06-26 21:32:26,659 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2021-06-26 21:32:26,727 INFO impl.YarnClientImpl: Submitted application application_1624742957627_0002\n",
      "2021-06-26 21:32:26,779 INFO mapreduce.Job: The url to track the job: http://hadoop:8088/proxy/application_1624742957627_0002/\n",
      "2021-06-26 21:32:26,779 INFO mapreduce.Job: Running job: job_1624742957627_0002\n",
      "2021-06-26 21:32:31,919 INFO mapreduce.Job: Job job_1624742957627_0002 running in uber mode : false\n",
      "2021-06-26 21:32:31,922 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2021-06-26 21:32:44,086 INFO mapreduce.Job:  map 17% reduce 0%\n",
      "2021-06-26 21:32:45,095 INFO mapreduce.Job:  map 33% reduce 0%\n",
      "2021-06-26 21:32:48,125 INFO mapreduce.Job:  map 50% reduce 0%\n",
      "2021-06-26 21:32:50,137 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "2021-06-26 21:32:51,142 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2021-06-26 21:32:52,154 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2021-06-26 21:32:52,175 INFO mapreduce.Job: Job job_1624742957627_0002 completed successfully\n",
      "2021-06-26 21:32:52,280 INFO mapreduce.Job: Counters: 55\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=249867\n",
      "\t\tFILE: Number of bytes written=2044638\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=157780752\n",
      "\t\tHDFS: Number of bytes written=16655\n",
      "\t\tHDFS: Number of read operations=23\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=7\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=7\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=174832\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=9434\n",
      "\t\tTotal time spent by all map tasks (ms)=87416\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4717\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=87416\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4717\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=22378496\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1207552\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=240358\n",
      "\t\tMap output records=14763424\n",
      "\t\tMap output bytes=216340730\n",
      "\t\tMap output materialized bytes=149931\n",
      "\t\tInput split bytes=714\n",
      "\t\tCombine input records=14763424\n",
      "\t\tCombine output records=9000\n",
      "\t\tReduce input groups=1000\n",
      "\t\tReduce shuffle bytes=149931\n",
      "\t\tReduce input records=9000\n",
      "\t\tReduce output records=1000\n",
      "\t\tSpilled Records=24000\n",
      "\t\tShuffled Maps =6\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=6\n",
      "\t\tGC time elapsed (ms)=5871\n",
      "\t\tCPU time spent (ms)=53800\n",
      "\t\tPhysical memory (bytes) snapshot=1943678976\n",
      "\t\tVirtual memory (bytes) snapshot=13598539776\n",
      "\t\tTotal committed heap usage (bytes)=1343750144\n",
      "\t\tPeak Map Physical memory (bytes)=295755776\n",
      "\t\tPeak Map Virtual memory (bytes)=1944506368\n",
      "\t\tPeak Reduce Physical memory (bytes)=184823808\n",
      "\t\tPeak Reduce Virtual memory (bytes)=1947717632\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=157780038\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=16655\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/hadoop/share/hadoop/mapreduce\n",
    "\n",
    "# hadoop jar ./hadoop-mapreduce-examples-3.2.1.jar\n",
    "\n",
    "# randomwriter: A map/reduce program that writes 10GB of random data per node\n",
    "# configured for 150MB of random text / 50 MB per map (3 maps)\n",
    "hadoop jar ./hadoop-mapreduce-examples-3.2.2.jar randomtextwriter \\\n",
    "  -D mapreduce.randomtextwriter.totalbytes=157286400 \\\n",
    "  -D mapreduce.randomtextwriter.bytespermap=52428800 \\\n",
    "  -D mapreduce.output.fileoutputformat.compress=false \\\n",
    "  -outFormat org.apache.hadoop.mapreduce.lib.output.TextOutputFormat \\\n",
    "  randomtext\n",
    "\n",
    "# wordcount: A map/reduce program that counts the words in the input files\n",
    "hadoop jar ./hadoop-mapreduce-examples-3.2.2.jar wordcount randomtext randomtextcount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent 124ms computing base-splits.\n",
      "Spent 2ms computing TeraScheduler splits.\n",
      "Computing input splits took 128ms\n",
      "Sampling 6 splits of 6\n",
      "Making 1 from 99996 sampled records\n",
      "Computing parititions took 288ms\n",
      "Spent 418ms computing partitions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-26 21:34:37,134 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:34:37,270 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n",
      "2021-06-26 21:34:37,447 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0003\n",
      "2021-06-26 21:34:37,641 INFO terasort.TeraGen: Generating 2000000 using 2\n",
      "2021-06-26 21:34:37,738 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2021-06-26 21:34:37,878 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1624742957627_0003\n",
      "2021-06-26 21:34:37,879 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2021-06-26 21:34:38,022 INFO conf.Configuration: resource-types.xml not found\n",
      "2021-06-26 21:34:38,023 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2021-06-26 21:34:38,080 INFO impl.YarnClientImpl: Submitted application application_1624742957627_0003\n",
      "2021-06-26 21:34:38,111 INFO mapreduce.Job: The url to track the job: http://hadoop:8088/proxy/application_1624742957627_0003/\n",
      "2021-06-26 21:34:38,111 INFO mapreduce.Job: Running job: job_1624742957627_0003\n",
      "2021-06-26 21:34:43,218 INFO mapreduce.Job: Job job_1624742957627_0003 running in uber mode : false\n",
      "2021-06-26 21:34:43,221 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2021-06-26 21:34:50,363 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2021-06-26 21:34:51,392 INFO mapreduce.Job: Job job_1624742957627_0003 completed successfully\n",
      "2021-06-26 21:34:51,483 INFO mapreduce.Job: Counters: 34\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=469178\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=167\n",
      "\t\tHDFS: Number of bytes written=200000000\n",
      "\t\tHDFS: Number of read operations=12\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tOther local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=20746\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=10373\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10373\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=2655488\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=2000000\n",
      "\t\tMap output records=2000000\n",
      "\t\tInput split bytes=167\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=271\n",
      "\t\tCPU time spent (ms)=5980\n",
      "\t\tPhysical memory (bytes) snapshot=369741824\n",
      "\t\tVirtual memory (bytes) snapshot=3888361472\n",
      "\t\tTotal committed heap usage (bytes)=173015040\n",
      "\t\tPeak Map Physical memory (bytes)=187977728\n",
      "\t\tPeak Map Virtual memory (bytes)=1944707072\n",
      "\torg.apache.hadoop.examples.terasort.TeraGen$Counters\n",
      "\t\tCHECKSUM=4296625497551440\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=200000000\n",
      "2021-06-26 21:34:52,566 INFO terasort.TeraSort: starting\n",
      "2021-06-26 21:34:53,263 INFO input.FileInputFormat: Total input files to process : 2\n",
      "2021-06-26 21:34:53,725 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:34:53,856 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n",
      "2021-06-26 21:34:53,985 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0004\n",
      "2021-06-26 21:34:54,247 INFO mapreduce.JobSubmitter: number of splits:6\n",
      "2021-06-26 21:34:54,405 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1624742957627_0004\n",
      "2021-06-26 21:34:54,406 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2021-06-26 21:34:54,554 INFO conf.Configuration: resource-types.xml not found\n",
      "2021-06-26 21:34:54,554 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2021-06-26 21:34:54,605 INFO impl.YarnClientImpl: Submitted application application_1624742957627_0004\n",
      "2021-06-26 21:34:54,638 INFO mapreduce.Job: The url to track the job: http://hadoop:8088/proxy/application_1624742957627_0004/\n",
      "2021-06-26 21:34:54,638 INFO mapreduce.Job: Running job: job_1624742957627_0004\n",
      "2021-06-26 21:35:01,771 INFO mapreduce.Job: Job job_1624742957627_0004 running in uber mode : false\n",
      "2021-06-26 21:35:01,774 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2021-06-26 21:35:09,889 INFO mapreduce.Job:  map 83% reduce 0%\n",
      "2021-06-26 21:35:10,903 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2021-06-26 21:35:19,961 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2021-06-26 21:35:20,993 INFO mapreduce.Job: Job job_1624742957627_0004 completed successfully\n",
      "2021-06-26 21:35:21,087 INFO mapreduce.Job: Counters: 55\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=208000036\n",
      "\t\tFILE: Number of bytes written=417652045\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=200000732\n",
      "\t\tHDFS: Number of bytes written=200000000\n",
      "\t\tHDFS: Number of read operations=23\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=6\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=6\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=79246\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=15124\n",
      "\t\tTotal time spent by all map tasks (ms)=39623\n",
      "\t\tTotal time spent by all reduce tasks (ms)=7562\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=39623\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=7562\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10143488\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1935872\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=2000000\n",
      "\t\tMap output records=2000000\n",
      "\t\tMap output bytes=204000000\n",
      "\t\tMap output materialized bytes=208000036\n",
      "\t\tInput split bytes=732\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2000000\n",
      "\t\tReduce shuffle bytes=208000036\n",
      "\t\tReduce input records=2000000\n",
      "\t\tReduce output records=2000000\n",
      "\t\tSpilled Records=4000000\n",
      "\t\tShuffled Maps =6\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=6\n",
      "\t\tGC time elapsed (ms)=1336\n",
      "\t\tCPU time spent (ms)=19760\n",
      "\t\tPhysical memory (bytes) snapshot=1918447616\n",
      "\t\tVirtual memory (bytes) snapshot=13582516224\n",
      "\t\tTotal committed heap usage (bytes)=1269301248\n",
      "\t\tPeak Map Physical memory (bytes)=289443840\n",
      "\t\tPeak Map Virtual memory (bytes)=1940979712\n",
      "\t\tPeak Reduce Physical memory (bytes)=207056896\n",
      "\t\tPeak Reduce Virtual memory (bytes)=1949016064\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=200000000\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=200000000\n",
      "2021-06-26 21:35:21,089 INFO terasort.TeraSort: done\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/hadoop/share/hadoop/mapreduce\n",
    "\n",
    "# Teragen - 200MB\n",
    "hadoop jar ./hadoop-mapreduce-examples-3.2.2.jar teragen \\\n",
    "  2000000 \\\n",
    "  teragenoutput\n",
    "\n",
    "# Terasort\n",
    "hadoop jar ./hadoop-mapreduce-examples-3.2.2.jar terasort \\\n",
    "  teragenoutput terasortoutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YARN - CLI\n",
    "\n",
    "- https://hadoop.apache.org/docs/r3.2.1/hadoop-yarn/hadoop-yarn-site/YarnCommands.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: yarn [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]\n",
      " or    yarn [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]\n",
      "  where CLASSNAME is a user-provided Java class\n",
      "\n",
      "  OPTIONS is none or any of:\n",
      "\n",
      "--buildpaths                       attempt to add class files from build tree\n",
      "--config dir                       Hadoop config directory\n",
      "--daemon (start|status|stop)       operate on a daemon\n",
      "--debug                            turn on shell script debug mode\n",
      "--help                             usage information\n",
      "--hostnames list[,of,host,names]   hosts to use in worker mode\n",
      "--hosts filename                   list of hosts to use in worker mode\n",
      "--loglevel level                   set the log4j level for this command\n",
      "--workers                          turn on worker mode\n",
      "\n",
      "  SUBCOMMAND is one of:\n",
      "\n",
      "\n",
      "    Admin Commands:\n",
      "\n",
      "daemonlog            get/set the log level for each daemon\n",
      "node                 prints node report(s)\n",
      "rmadmin              admin tools\n",
      "scmadmin             SharedCacheManager admin tools\n",
      "\n",
      "    Client Commands:\n",
      "\n",
      "applicationattempt   prints applicationattempt(s) report\n",
      "app|application      prints application(s) report/kill application/manage\n",
      "                     long running application\n",
      "classpath            prints the class path needed to get the hadoop jar and\n",
      "                     the required libraries\n",
      "cluster              prints cluster information\n",
      "container            prints container(s) report\n",
      "envvars              display computed Hadoop environment variables\n",
      "jar <jar>            run a jar file\n",
      "logs                 dump container logs\n",
      "nodeattributes       node attributes cli client\n",
      "queue                prints queue information\n",
      "schedulerconf        Updates scheduler configuration\n",
      "timelinereader       run the timeline reader server\n",
      "top                  view cluster information\n",
      "version              print the version\n",
      "\n",
      "    Daemon Commands:\n",
      "\n",
      "nodemanager          run a nodemanager on each worker\n",
      "proxyserver          run the web app proxy server\n",
      "registrydns          run the registry DNS server\n",
      "resourcemanager      run the ResourceManager\n",
      "router               run the Router daemon\n",
      "sharedcachemanager   run the SharedCacheManager daemon\n",
      "timelineserver       run the timeline server\n",
      "\n",
      "SUBCOMMAND may print help when invoked w/o parameters or with -h.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "yarn help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List cluster node status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes:3\n",
      "         Node-Id\t     Node-State\tNode-Http-Address\tNumber-of-Running-Containers\n",
      "   hadoop1:46409\t        RUNNING\t     hadoop1:8042\t                           0\n",
      "Detailed Node Information :\n",
      "\tConfigured Resources : <memory:1536, vCores:8>\n",
      "\tAllocated Resources : <memory:0, vCores:0>\n",
      "\tResource Utilization by Node : PMem:10834 MB, VMem:11087 MB, VCores:0.35309792\n",
      "\tResource Utilization by Containers : PMem:0 MB, VMem:0 MB, VCores:0.0\n",
      "\tNode-Labels : \n",
      "   hadoop2:46223\t        RUNNING\t     hadoop2:8042\t                           0\n",
      "Detailed Node Information :\n",
      "\tConfigured Resources : <memory:1536, vCores:8>\n",
      "\tAllocated Resources : <memory:0, vCores:0>\n",
      "\tResource Utilization by Node : PMem:10840 MB, VMem:11093 MB, VCores:0.38922158\n",
      "\tResource Utilization by Containers : PMem:0 MB, VMem:0 MB, VCores:0.0\n",
      "\tNode-Labels : \n",
      "   hadoop3:40733\t        RUNNING\t     hadoop3:8042\t                           0\n",
      "Detailed Node Information :\n",
      "\tConfigured Resources : <memory:1536, vCores:8>\n",
      "\tAllocated Resources : <memory:0, vCores:0>\n",
      "\tResource Utilization by Node : PMem:10834 MB, VMem:11087 MB, VCores:0.3532156\n",
      "\tResource Utilization by Containers : PMem:0 MB, VMem:0 MB, VCores:0.0\n",
      "\tNode-Labels : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-26 21:36:15,400 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:36:15,550 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n",
      "2021-06-26 21:36:15,677 INFO conf.Configuration: resource-types.xml not found\n",
      "2021-06-26 21:36:15,678 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "yarn node -all -list -showDetails\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hadoop1\n",
      "hadoop2\n",
      "hadoop3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat /opt/hadoop/etc/hadoop/workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of applications (application-types: [], states: [NEW, NEW_SAVING, SUBMITTED, ACCEPTED, RUNNING, FINISHED, FAILED, KILLED] and tags: []):4\n",
      "                Application-Id\t    Application-Name\t    Application-Type\t      User\t     Queue\t             State\t       Final-State\t       Progress\t                       Tracking-URL\n",
      "application_1624742957627_0004\t            TeraSort\t           MAPREDUCE\t    hadoop\t   default\t          FINISHED\t         SUCCEEDED\t           100%\thttp://hadoop3:19888/jobhistory/job/job_1624742957627_0004\n",
      "application_1624742957627_0003\t             TeraGen\t           MAPREDUCE\t    hadoop\t   default\t          FINISHED\t         SUCCEEDED\t           100%\thttp://hadoop2:19888/jobhistory/job/job_1624742957627_0003\n",
      "application_1624742957627_0002\t          word count\t           MAPREDUCE\t    hadoop\t   default\t          FINISHED\t         SUCCEEDED\t           100%\thttp://hadoop3:19888/jobhistory/job/job_1624742957627_0002\n",
      "application_1624742957627_0001\t  random-text-writer\t           MAPREDUCE\t    hadoop\t   default\t          FINISHED\t         SUCCEEDED\t           100%\thttp://hadoop3:19888/jobhistory/job/job_1624742957627_0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-26 21:38:31,668 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:38:31,823 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Current applications (running or accepted)\n",
    "# yarn app -list\n",
    "# Applications already executed\n",
    "yarn app -list -appStates ALL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List queue status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue Information : \n",
      "Queue Name : default\n",
      "\tState : RUNNING\n",
      "\tCapacity : 100.00%\n",
      "\tCurrent Capacity : .00%\n",
      "\tMaximum Capacity : 100.00%\n",
      "\tDefault Node Label expression : <DEFAULT_PARTITION>\n",
      "\tAccessible Node Labels : *\n",
      "\tPreemption : disabled\n",
      "\tIntra-queue Preemption : disabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-26 21:39:20,080 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:39:20,236 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "yarn queue -status default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get application log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting logs for application_1624742957627_0001\n",
      "Container: container_1624742957627_0001_01_000002 on hadoop1_46409\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:directory.info\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:1989\n",
      "LogContents:\n",
      "ls -l:\n",
      "total 32\n",
      "-rw-r--r-- 1 hadoop hadoop  129 Jun 26 21:31 container_tokens\n",
      "-rwx------ 1 hadoop hadoop  733 Jun 26 21:31 default_container_executor.sh\n",
      "-rwx------ 1 hadoop hadoop  678 Jun 26 21:31 default_container_executor_session.sh\n",
      "lrwxrwxrwx 1 hadoop hadoop  109 Jun 26 21:31 job.jar -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/10/job.jar\n",
      "lrwxrwxrwx 1 hadoop hadoop  109 Jun 26 21:31 job.xml -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/11/job.xml\n",
      "-rwx------ 1 hadoop hadoop 5108 Jun 26 21:31 launch_container.sh\n",
      "drwx--x--- 2 hadoop hadoop 4096 Jun 26 21:31 tmp\n",
      "find -L . -maxdepth 5 -ls:\n",
      "  1409836      4 drwx--x---   3 hadoop   hadoop       4096 Jun 26 21:31 .\n",
      "  1381372    196 -r-x------   1 hadoop   hadoop     200592 Jun 26 21:31 ./job.xml\n",
      "  1381384      4 -rwx------   1 hadoop   hadoop        733 Jun 26 21:31 ./default_container_executor.sh\n",
      "  1409838      4 drwx--x---   2 hadoop   hadoop       4096 Jun 26 21:31 ./tmp\n",
      "  1381378      4 -rw-r--r--   1 hadoop   hadoop        129 Jun 26 21:31 ./container_tokens\n",
      "  1381383      4 -rw-r--r--   1 hadoop   hadoop         16 Jun 26 21:31 ./.default_container_executor_session.sh.crc\n",
      "  1381379      4 -rw-r--r--   1 hadoop   hadoop         12 Jun 26 21:31 ./.container_tokens.crc\n",
      "  1381380      8 -rwx------   1 hadoop   hadoop       5108 Jun 26 21:31 ./launch_container.sh\n",
      "  1381381      4 -rw-r--r--   1 hadoop   hadoop         48 Jun 26 21:31 ./.launch_container.sh.crc\n",
      "  1381385      4 -rw-r--r--   1 hadoop   hadoop         16 Jun 26 21:31 ./.default_container_executor.sh.crc\n",
      "  1409819      4 drwx------   2 hadoop   hadoop       4096 Jun 26 21:31 ./job.jar\n",
      "  1381370    312 -r-x------   1 hadoop   hadoop     316483 Jun 26 21:31 ./job.jar/job.jar\n",
      "  1381382      4 -rwx------   1 hadoop   hadoop        678 Jun 26 21:31 ./default_container_executor_session.sh\n",
      "broken symlinks(find -L . -maxdepth 5 -type l -ls):\n",
      "\n",
      "End of LogType:directory.info\n",
      "*******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000002 on hadoop1_46409\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:launch_container.sh\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:5108\n",
      "LogContents:\n",
      "#!/bin/bash\n",
      "\n",
      "set -o pipefail -e\n",
      "export PRELAUNCH_OUT=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/prelaunch.out\"\n",
      "exec >\"${PRELAUNCH_OUT}\"\n",
      "export PRELAUNCH_ERR=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/prelaunch.err\"\n",
      "exec 2>\"${PRELAUNCH_ERR}\"\n",
      "echo \"Setting up env variables\"\n",
      "export JAVA_HOME=${JAVA_HOME:-\"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"}\n",
      "export HADOOP_COMMON_HOME=${HADOOP_COMMON_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_HDFS_HOME=${HADOOP_HDFS_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-\"/opt/hadoop/etc/hadoop\"}\n",
      "export HADOOP_YARN_HOME=${HADOOP_YARN_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_HOME=${HADOOP_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export PATH=${PATH:-\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\"}\n",
      "export HADOOP_TOKEN_FILE_LOCATION=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000002/container_tokens\"\n",
      "export CONTAINER_ID=\"container_1624742957627_0001_01_000002\"\n",
      "export NM_PORT=\"46409\"\n",
      "export NM_HOST=\"hadoop1\"\n",
      "export NM_HTTP_PORT=\"8042\"\n",
      "export LOCAL_DIRS=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001\"\n",
      "export LOCAL_USER_DIRS=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/\"\n",
      "export LOG_DIRS=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002\"\n",
      "export USER=\"hadoop\"\n",
      "export LOGNAME=\"hadoop\"\n",
      "export HOME=\"/home/\"\n",
      "export PWD=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000002\"\n",
      "export LOCALIZATION_COUNTERS=\"518651,0,2,0,374\"\n",
      "export JVM_PID=\"$$\"\n",
      "export MALLOC_ARENA_MAX=\"4\"\n",
      "export NM_AUX_SERVICE_mapreduce_shuffle=\"AAA0+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\n",
      "export STDOUT_LOGFILE_ENV=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/stdout\"\n",
      "export SHELL=\"/bin/bash\"\n",
      "export HADOOP_ROOT_LOGGER=\"INFO,console\"\n",
      "export CLASSPATH=\"$PWD:$HADOOP_CONF_DIR:$HADOOP_COMMON_HOME/share/hadoop/common/*:$HADOOP_COMMON_HOME/share/hadoop/common/lib/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*:$HADOOP_YARN_HOME/share/hadoop/yarn/*:$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:job.jar/*:job.jar/classes/:job.jar/lib/*:$PWD/*\"\n",
      "export LD_LIBRARY_PATH=\"$PWD:$HADOOP_COMMON_HOME/lib/native\"\n",
      "export STDERR_LOGFILE_ENV=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/stderr\"\n",
      "export HADOOP_CLIENT_OPTS=\"\"\n",
      "echo \"Setting up job resources\"\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/11/job.xml\" \"job.xml\"\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/10/job.jar\" \"job.jar\"\n",
      "echo \"Copying debugging information\"\n",
      "# Creating copy of launch script\n",
      "cp \"launch_container.sh\" \"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/launch_container.sh\"\n",
      "chmod 640 \"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/launch_container.sh\"\n",
      "# Determining directory contents\n",
      "echo \"ls -l:\" 1>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/directory.info\"\n",
      "ls -l 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/directory.info\"\n",
      "echo \"find -L . -maxdepth 5 -ls:\" 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/directory.info\"\n",
      "find -L . -maxdepth 5 -ls 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/directory.info\"\n",
      "echo \"broken symlinks(find -L . -maxdepth 5 -type l -ls):\" 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/directory.info\"\n",
      "find -L . -maxdepth 5 -type l -ls 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/directory.info\"\n",
      "echo \"Launching container\"\n",
      "exec /bin/bash -c \"$JAVA_HOME/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx205m -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.17.0.6 42871 attempt_1624742957627_0001_m_000000_0 2 1>/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/stdout 2>/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000002/stderr \"\n",
      "\n",
      "End of LogType:launch_container.sh\n",
      "************************************************************************************\n",
      "\n",
      "\n",
      "End of LogType:prelaunch.err\n",
      "******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000002 on hadoop1_46409\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:prelaunch.out\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:100\n",
      "LogContents:\n",
      "Setting up env variables\n",
      "Setting up job resources\n",
      "Copying debugging information\n",
      "Launching container\n",
      "\n",
      "End of LogType:prelaunch.out\n",
      "******************************************************************************\n",
      "\n",
      "\n",
      "End of LogType:stderr\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "End of LogType:stdout\n",
      "***********************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000002 on hadoop1_46409\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:syslog\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:21939\n",
      "LogContents:\n",
      "2021-06-26 21:31:55,192 INFO [main] org.apache.hadoop.security.SecurityUtil: Updating Configuration\n",
      "2021-06-26 21:31:55,281 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2021-06-26 21:31:55,386 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2021-06-26 21:31:55,386 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started\n",
      "2021-06-26 21:31:55,442 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens: [Kind: mapreduce.job, Service: job_1624742957627_0001, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1e800aaa)]\n",
      "2021-06-26 21:31:55,484 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.\n",
      "2021-06-26 21:31:55,728 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001\n",
      "2021-06-26 21:31:56,041 INFO [main] org.apache.hadoop.mapred.YarnChild: \n",
      "/************************************************************\n",
      "[system properties]\n",
      "os.name: Linux\n",
      "os.version: 5.4.0-77-generic\n",
      "java.home: /usr/lib/jvm/java-8-openjdk-amd64/jre\n",
      "java.runtime.version: 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10\n",
      "java.vendor: Private Build\n",
      "java.version: 1.8.0_292\n",
      "java.vm.name: OpenJDK 64-Bit Server VM\n",
      "java.class.path: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000002:/opt/hadoop/etc/hadoop:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-kms-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-nfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-compress-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000002/job.jar\n",
      "java.io.tmpdir: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000002/tmp\n",
      "user.dir: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000002\n",
      "user.name: hadoop\n",
      "************************************************************/\n",
      "2021-06-26 21:31:56,044 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2021-06-26 21:31:56,603 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2021-06-26 21:31:56,604 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-06-26 21:31:56,616 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-06-26 21:31:56,732 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://hadoop:9000/user/hadoop/randomtext/dummy-split-0:0+1\n",
      "2021-06-26 21:31:57,674 INFO [main] org.apache.hadoop.mapred.Task: Task:attempt_1624742957627_0001_m_000000_0 is done. And is in the process of committing\n",
      "2021-06-26 21:31:57,684 INFO [main] org.apache.hadoop.mapred.Task: Task attempt_1624742957627_0001_m_000000_0 is allowed to commit now\n",
      "2021-06-26 21:31:57,711 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_1624742957627_0001_m_000000_0' to hdfs://hadoop:9000/user/hadoop/randomtext\n",
      "2021-06-26 21:31:57,722 INFO [main] org.apache.hadoop.mapred.Task: Task 'attempt_1624742957627_0001_m_000000_0' done.\n",
      "2021-06-26 21:31:57,730 INFO [main] org.apache.hadoop.mapred.Task: Final Counters for attempt_1624742957627_0001_m_000000_0: Counters: 28\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=234786\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=120\n",
      "\t\tHDFS: Number of bytes written=52589341\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1\n",
      "\t\tMap output records=80252\n",
      "\t\tInput split bytes=120\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=185\n",
      "\t\tCPU time spent (ms)=2040\n",
      "\t\tPhysical memory (bytes) snapshot=191705088\n",
      "\t\tVirtual memory (bytes) snapshot=1946849280\n",
      "\t\tTotal committed heap usage (bytes)=92274688\n",
      "\t\tPeak Map Physical memory (bytes)=191705088\n",
      "\t\tPeak Map Virtual memory (bytes)=1946849280\n",
      "\torg.apache.hadoop.examples.RandomTextWriter$Counters\n",
      "\t\tBYTES_WRITTEN=52428837\n",
      "\t\tRECORDS_WRITTEN=80252\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=52589341\n",
      "2021-06-26 21:31:57,731 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...\n",
      "2021-06-26 21:31:57,732 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.\n",
      "2021-06-26 21:31:57,732 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.\n",
      "\n",
      "End of LogType:syslog\n",
      "***********************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000003 on hadoop2_46223\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:directory.info\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:1989\n",
      "LogContents:\n",
      "ls -l:\n",
      "total 32\n",
      "-rw-r--r-- 1 hadoop hadoop  129 Jun 26 21:31 container_tokens\n",
      "-rwx------ 1 hadoop hadoop  733 Jun 26 21:31 default_container_executor.sh\n",
      "-rwx------ 1 hadoop hadoop  678 Jun 26 21:31 default_container_executor_session.sh\n",
      "lrwxrwxrwx 1 hadoop hadoop  109 Jun 26 21:31 job.jar -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/10/job.jar\n",
      "lrwxrwxrwx 1 hadoop hadoop  109 Jun 26 21:31 job.xml -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/11/job.xml\n",
      "-rwx------ 1 hadoop hadoop 5108 Jun 26 21:31 launch_container.sh\n",
      "drwx--x--- 2 hadoop hadoop 4096 Jun 26 21:31 tmp\n",
      "find -L . -maxdepth 5 -ls:\n",
      "  1409842      4 drwx--x---   3 hadoop   hadoop       4096 Jun 26 21:31 .\n",
      "  1381396    196 -r-x------   1 hadoop   hadoop     200592 Jun 26 21:31 ./job.xml\n",
      "  1381408      4 -rwx------   1 hadoop   hadoop        733 Jun 26 21:31 ./default_container_executor.sh\n",
      "  1409844      4 drwx--x---   2 hadoop   hadoop       4096 Jun 26 21:31 ./tmp\n",
      "  1381402      4 -rw-r--r--   1 hadoop   hadoop        129 Jun 26 21:31 ./container_tokens\n",
      "  1381407      4 -rw-r--r--   1 hadoop   hadoop         16 Jun 26 21:31 ./.default_container_executor_session.sh.crc\n",
      "  1381403      4 -rw-r--r--   1 hadoop   hadoop         12 Jun 26 21:31 ./.container_tokens.crc\n",
      "  1381404      8 -rwx------   1 hadoop   hadoop       5108 Jun 26 21:31 ./launch_container.sh\n",
      "  1381405      4 -rw-r--r--   1 hadoop   hadoop         48 Jun 26 21:31 ./.launch_container.sh.crc\n",
      "  1381409      4 -rw-r--r--   1 hadoop   hadoop         16 Jun 26 21:31 ./.default_container_executor.sh.crc\n",
      "  1409821      4 drwx------   2 hadoop   hadoop       4096 Jun 26 21:31 ./job.jar\n",
      "  1381371    312 -r-x------   1 hadoop   hadoop     316483 Jun 26 21:31 ./job.jar/job.jar\n",
      "  1381406      4 -rwx------   1 hadoop   hadoop        678 Jun 26 21:31 ./default_container_executor_session.sh\n",
      "broken symlinks(find -L . -maxdepth 5 -type l -ls):\n",
      "\n",
      "End of LogType:directory.info\n",
      "*******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000003 on hadoop2_46223\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:launch_container.sh\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:5108\n",
      "LogContents:\n",
      "#!/bin/bash\n",
      "\n",
      "set -o pipefail -e\n",
      "export PRELAUNCH_OUT=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/prelaunch.out\"\n",
      "exec >\"${PRELAUNCH_OUT}\"\n",
      "export PRELAUNCH_ERR=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/prelaunch.err\"\n",
      "exec 2>\"${PRELAUNCH_ERR}\"\n",
      "echo \"Setting up env variables\"\n",
      "export JAVA_HOME=${JAVA_HOME:-\"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"}\n",
      "export HADOOP_COMMON_HOME=${HADOOP_COMMON_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_HDFS_HOME=${HADOOP_HDFS_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-\"/opt/hadoop/etc/hadoop\"}\n",
      "export HADOOP_YARN_HOME=${HADOOP_YARN_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_HOME=${HADOOP_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export PATH=${PATH:-\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\"}\n",
      "export HADOOP_TOKEN_FILE_LOCATION=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000003/container_tokens\"\n",
      "export CONTAINER_ID=\"container_1624742957627_0001_01_000003\"\n",
      "export NM_PORT=\"46223\"\n",
      "export NM_HOST=\"hadoop2\"\n",
      "export NM_HTTP_PORT=\"8042\"\n",
      "export LOCAL_DIRS=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001\"\n",
      "export LOCAL_USER_DIRS=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/\"\n",
      "export LOG_DIRS=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003\"\n",
      "export USER=\"hadoop\"\n",
      "export LOGNAME=\"hadoop\"\n",
      "export HOME=\"/home/\"\n",
      "export PWD=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000003\"\n",
      "export LOCALIZATION_COUNTERS=\"518651,0,2,0,404\"\n",
      "export JVM_PID=\"$$\"\n",
      "export MALLOC_ARENA_MAX=\"4\"\n",
      "export NM_AUX_SERVICE_mapreduce_shuffle=\"AAA0+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\n",
      "export STDOUT_LOGFILE_ENV=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/stdout\"\n",
      "export SHELL=\"/bin/bash\"\n",
      "export HADOOP_ROOT_LOGGER=\"INFO,console\"\n",
      "export CLASSPATH=\"$PWD:$HADOOP_CONF_DIR:$HADOOP_COMMON_HOME/share/hadoop/common/*:$HADOOP_COMMON_HOME/share/hadoop/common/lib/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*:$HADOOP_YARN_HOME/share/hadoop/yarn/*:$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:job.jar/*:job.jar/classes/:job.jar/lib/*:$PWD/*\"\n",
      "export LD_LIBRARY_PATH=\"$PWD:$HADOOP_COMMON_HOME/lib/native\"\n",
      "export STDERR_LOGFILE_ENV=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/stderr\"\n",
      "export HADOOP_CLIENT_OPTS=\"\"\n",
      "echo \"Setting up job resources\"\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/11/job.xml\" \"job.xml\"\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/10/job.jar\" \"job.jar\"\n",
      "echo \"Copying debugging information\"\n",
      "# Creating copy of launch script\n",
      "cp \"launch_container.sh\" \"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/launch_container.sh\"\n",
      "chmod 640 \"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/launch_container.sh\"\n",
      "# Determining directory contents\n",
      "echo \"ls -l:\" 1>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/directory.info\"\n",
      "ls -l 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/directory.info\"\n",
      "echo \"find -L . -maxdepth 5 -ls:\" 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/directory.info\"\n",
      "find -L . -maxdepth 5 -ls 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/directory.info\"\n",
      "echo \"broken symlinks(find -L . -maxdepth 5 -type l -ls):\" 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/directory.info\"\n",
      "find -L . -maxdepth 5 -type l -ls 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/directory.info\"\n",
      "echo \"Launching container\"\n",
      "exec /bin/bash -c \"$JAVA_HOME/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx205m -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.17.0.6 42871 attempt_1624742957627_0001_m_000001_0 3 1>/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/stdout 2>/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000003/stderr \"\n",
      "\n",
      "End of LogType:launch_container.sh\n",
      "************************************************************************************\n",
      "\n",
      "\n",
      "End of LogType:prelaunch.err\n",
      "******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000003 on hadoop2_46223\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:prelaunch.out\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:100\n",
      "LogContents:\n",
      "Setting up env variables\n",
      "Setting up job resources\n",
      "Copying debugging information\n",
      "Launching container\n",
      "\n",
      "End of LogType:prelaunch.out\n",
      "******************************************************************************\n",
      "\n",
      "\n",
      "End of LogType:stderr\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "End of LogType:stdout\n",
      "***********************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000003 on hadoop2_46223\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:syslog\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:21939\n",
      "LogContents:\n",
      "2021-06-26 21:31:55,302 INFO [main] org.apache.hadoop.security.SecurityUtil: Updating Configuration\n",
      "2021-06-26 21:31:55,385 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2021-06-26 21:31:55,522 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2021-06-26 21:31:55,522 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started\n",
      "2021-06-26 21:31:55,599 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens: [Kind: mapreduce.job, Service: job_1624742957627_0001, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1e800aaa)]\n",
      "2021-06-26 21:31:55,647 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.\n",
      "2021-06-26 21:31:55,905 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001\n",
      "2021-06-26 21:31:56,259 INFO [main] org.apache.hadoop.mapred.YarnChild: \n",
      "/************************************************************\n",
      "[system properties]\n",
      "os.name: Linux\n",
      "os.version: 5.4.0-77-generic\n",
      "java.home: /usr/lib/jvm/java-8-openjdk-amd64/jre\n",
      "java.runtime.version: 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10\n",
      "java.vendor: Private Build\n",
      "java.version: 1.8.0_292\n",
      "java.vm.name: OpenJDK 64-Bit Server VM\n",
      "java.class.path: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000003:/opt/hadoop/etc/hadoop:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-kms-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-nfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-compress-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000003/job.jar\n",
      "java.io.tmpdir: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000003/tmp\n",
      "user.dir: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000003\n",
      "user.name: hadoop\n",
      "************************************************************/\n",
      "2021-06-26 21:31:56,261 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2021-06-26 21:31:56,683 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2021-06-26 21:31:56,683 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-06-26 21:31:56,695 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-06-26 21:31:56,835 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://hadoop:9000/user/hadoop/randomtext/dummy-split-1:0+1\n",
      "2021-06-26 21:31:57,781 INFO [main] org.apache.hadoop.mapred.Task: Task:attempt_1624742957627_0001_m_000001_0 is done. And is in the process of committing\n",
      "2021-06-26 21:31:57,789 INFO [main] org.apache.hadoop.mapred.Task: Task attempt_1624742957627_0001_m_000001_0 is allowed to commit now\n",
      "2021-06-26 21:31:57,805 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_1624742957627_0001_m_000001_0' to hdfs://hadoop:9000/user/hadoop/randomtext\n",
      "2021-06-26 21:31:57,812 INFO [main] org.apache.hadoop.mapred.Task: Task 'attempt_1624742957627_0001_m_000001_0' done.\n",
      "2021-06-26 21:31:57,819 INFO [main] org.apache.hadoop.mapred.Task: Final Counters for attempt_1624742957627_0001_m_000001_0: Counters: 28\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=234786\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=120\n",
      "\t\tHDFS: Number of bytes written=52589317\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1\n",
      "\t\tMap output records=80089\n",
      "\t\tInput split bytes=120\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=124\n",
      "\t\tCPU time spent (ms)=2210\n",
      "\t\tPhysical memory (bytes) snapshot=182353920\n",
      "\t\tVirtual memory (bytes) snapshot=1944203264\n",
      "\t\tTotal committed heap usage (bytes)=85983232\n",
      "\t\tPeak Map Physical memory (bytes)=182353920\n",
      "\t\tPeak Map Virtual memory (bytes)=1944203264\n",
      "\torg.apache.hadoop.examples.RandomTextWriter$Counters\n",
      "\t\tBYTES_WRITTEN=52429139\n",
      "\t\tRECORDS_WRITTEN=80089\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=52589317\n",
      "2021-06-26 21:31:57,820 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...\n",
      "2021-06-26 21:31:57,820 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.\n",
      "2021-06-26 21:31:57,820 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.\n",
      "\n",
      "End of LogType:syslog\n",
      "***********************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000004 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:directory.info\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:1989\n",
      "LogContents:\n",
      "ls -l:\n",
      "total 32\n",
      "-rw-r--r-- 1 hadoop hadoop  129 Jun 26 21:31 container_tokens\n",
      "-rwx------ 1 hadoop hadoop  733 Jun 26 21:31 default_container_executor.sh\n",
      "-rwx------ 1 hadoop hadoop  678 Jun 26 21:31 default_container_executor_session.sh\n",
      "lrwxrwxrwx 1 hadoop hadoop  109 Jun 26 21:31 job.jar -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/11/job.jar\n",
      "lrwxrwxrwx 1 hadoop hadoop  109 Jun 26 21:31 job.xml -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/13/job.xml\n",
      "-rwx------ 1 hadoop hadoop 5106 Jun 26 21:31 launch_container.sh\n",
      "drwx--x--- 2 hadoop hadoop 4096 Jun 26 21:31 tmp\n",
      "find -L . -maxdepth 5 -ls:\n",
      "  1409765      4 drwx--x---   3 hadoop   hadoop       4096 Jun 26 21:31 .\n",
      "  1381313    196 -r-x------   1 hadoop   hadoop     200592 Jun 26 21:31 ./job.xml\n",
      "  1381353      4 -rwx------   1 hadoop   hadoop        733 Jun 26 21:31 ./default_container_executor.sh\n",
      "  1409767      4 drwx--x---   2 hadoop   hadoop       4096 Jun 26 21:31 ./tmp\n",
      "  1381347      4 -rw-r--r--   1 hadoop   hadoop        129 Jun 26 21:31 ./container_tokens\n",
      "  1381352      4 -rw-r--r--   1 hadoop   hadoop         16 Jun 26 21:31 ./.default_container_executor_session.sh.crc\n",
      "  1381348      4 -rw-r--r--   1 hadoop   hadoop         12 Jun 26 21:31 ./.container_tokens.crc\n",
      "  1381349      8 -rwx------   1 hadoop   hadoop       5106 Jun 26 21:31 ./launch_container.sh\n",
      "  1381350      4 -rw-r--r--   1 hadoop   hadoop         48 Jun 26 21:31 ./.launch_container.sh.crc\n",
      "  1381354      4 -rw-r--r--   1 hadoop   hadoop         16 Jun 26 21:31 ./.default_container_executor.sh.crc\n",
      "  1409172      4 drwx------   2 hadoop   hadoop       4096 Jun 26 21:31 ./job.jar\n",
      "  1381310    312 -r-x------   1 hadoop   hadoop     316483 Jun 26 21:31 ./job.jar/job.jar\n",
      "  1381351      4 -rwx------   1 hadoop   hadoop        678 Jun 26 21:31 ./default_container_executor_session.sh\n",
      "broken symlinks(find -L . -maxdepth 5 -type l -ls):\n",
      "\n",
      "End of LogType:directory.info\n",
      "*******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000004 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:launch_container.sh\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:5106\n",
      "LogContents:\n",
      "#!/bin/bash\n",
      "\n",
      "set -o pipefail -e\n",
      "export PRELAUNCH_OUT=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/prelaunch.out\"\n",
      "exec >\"${PRELAUNCH_OUT}\"\n",
      "export PRELAUNCH_ERR=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/prelaunch.err\"\n",
      "exec 2>\"${PRELAUNCH_ERR}\"\n",
      "echo \"Setting up env variables\"\n",
      "export JAVA_HOME=${JAVA_HOME:-\"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"}\n",
      "export HADOOP_COMMON_HOME=${HADOOP_COMMON_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_HDFS_HOME=${HADOOP_HDFS_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-\"/opt/hadoop/etc/hadoop\"}\n",
      "export HADOOP_YARN_HOME=${HADOOP_YARN_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_HOME=${HADOOP_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export PATH=${PATH:-\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\"}\n",
      "export HADOOP_TOKEN_FILE_LOCATION=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000004/container_tokens\"\n",
      "export CONTAINER_ID=\"container_1624742957627_0001_01_000004\"\n",
      "export NM_PORT=\"40733\"\n",
      "export NM_HOST=\"hadoop3\"\n",
      "export NM_HTTP_PORT=\"8042\"\n",
      "export LOCAL_DIRS=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001\"\n",
      "export LOCAL_USER_DIRS=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/\"\n",
      "export LOG_DIRS=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004\"\n",
      "export USER=\"hadoop\"\n",
      "export LOGNAME=\"hadoop\"\n",
      "export HOME=\"/home/\"\n",
      "export PWD=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000004\"\n",
      "export LOCALIZATION_COUNTERS=\"0,518651,0,2,7\"\n",
      "export JVM_PID=\"$$\"\n",
      "export MALLOC_ARENA_MAX=\"4\"\n",
      "export NM_AUX_SERVICE_mapreduce_shuffle=\"AAA0+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\n",
      "export STDOUT_LOGFILE_ENV=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/stdout\"\n",
      "export SHELL=\"/bin/bash\"\n",
      "export HADOOP_ROOT_LOGGER=\"INFO,console\"\n",
      "export CLASSPATH=\"$PWD:$HADOOP_CONF_DIR:$HADOOP_COMMON_HOME/share/hadoop/common/*:$HADOOP_COMMON_HOME/share/hadoop/common/lib/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*:$HADOOP_YARN_HOME/share/hadoop/yarn/*:$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:job.jar/*:job.jar/classes/:job.jar/lib/*:$PWD/*\"\n",
      "export LD_LIBRARY_PATH=\"$PWD:$HADOOP_COMMON_HOME/lib/native\"\n",
      "export STDERR_LOGFILE_ENV=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/stderr\"\n",
      "export HADOOP_CLIENT_OPTS=\"\"\n",
      "echo \"Setting up job resources\"\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/11/job.jar\" \"job.jar\"\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/13/job.xml\" \"job.xml\"\n",
      "echo \"Copying debugging information\"\n",
      "# Creating copy of launch script\n",
      "cp \"launch_container.sh\" \"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/launch_container.sh\"\n",
      "chmod 640 \"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/launch_container.sh\"\n",
      "# Determining directory contents\n",
      "echo \"ls -l:\" 1>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/directory.info\"\n",
      "ls -l 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/directory.info\"\n",
      "echo \"find -L . -maxdepth 5 -ls:\" 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/directory.info\"\n",
      "find -L . -maxdepth 5 -ls 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/directory.info\"\n",
      "echo \"broken symlinks(find -L . -maxdepth 5 -type l -ls):\" 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/directory.info\"\n",
      "find -L . -maxdepth 5 -type l -ls 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/directory.info\"\n",
      "echo \"Launching container\"\n",
      "exec /bin/bash -c \"$JAVA_HOME/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx205m -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.17.0.6 42871 attempt_1624742957627_0001_m_000002_0 4 1>/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/stdout 2>/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000004/stderr \"\n",
      "\n",
      "End of LogType:launch_container.sh\n",
      "************************************************************************************\n",
      "\n",
      "\n",
      "End of LogType:prelaunch.err\n",
      "******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000004 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:prelaunch.out\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:100\n",
      "LogContents:\n",
      "Setting up env variables\n",
      "Setting up job resources\n",
      "Copying debugging information\n",
      "Launching container\n",
      "\n",
      "End of LogType:prelaunch.out\n",
      "******************************************************************************\n",
      "\n",
      "\n",
      "End of LogType:stderr\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "End of LogType:stdout\n",
      "***********************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000004 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:syslog\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:21939\n",
      "LogContents:\n",
      "2021-06-26 21:31:53,997 INFO [main] org.apache.hadoop.security.SecurityUtil: Updating Configuration\n",
      "2021-06-26 21:31:54,084 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2021-06-26 21:31:54,191 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2021-06-26 21:31:54,191 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system started\n",
      "2021-06-26 21:31:54,245 INFO [main] org.apache.hadoop.mapred.YarnChild: Executing with tokens: [Kind: mapreduce.job, Service: job_1624742957627_0001, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@1e800aaa)]\n",
      "2021-06-26 21:31:54,284 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.\n",
      "2021-06-26 21:31:54,473 INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001\n",
      "2021-06-26 21:31:54,663 INFO [main] org.apache.hadoop.mapred.YarnChild: \n",
      "/************************************************************\n",
      "[system properties]\n",
      "os.name: Linux\n",
      "os.version: 5.4.0-77-generic\n",
      "java.home: /usr/lib/jvm/java-8-openjdk-amd64/jre\n",
      "java.runtime.version: 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10\n",
      "java.vendor: Private Build\n",
      "java.version: 1.8.0_292\n",
      "java.vm.name: OpenJDK 64-Bit Server VM\n",
      "java.class.path: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000004:/opt/hadoop/etc/hadoop:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-kms-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-nfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-compress-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000004/job.jar\n",
      "java.io.tmpdir: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000004/tmp\n",
      "user.dir: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000004\n",
      "user.name: hadoop\n",
      "************************************************************/\n",
      "2021-06-26 21:31:54,665 INFO [main] org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2021-06-26 21:31:55,165 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2021-06-26 21:31:55,166 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-06-26 21:31:55,189 INFO [main] org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2021-06-26 21:31:55,361 INFO [main] org.apache.hadoop.mapred.MapTask: Processing split: hdfs://hadoop:9000/user/hadoop/randomtext/dummy-split-2:0+1\n",
      "2021-06-26 21:31:56,387 INFO [main] org.apache.hadoop.mapred.Task: Task:attempt_1624742957627_0001_m_000002_0 is done. And is in the process of committing\n",
      "2021-06-26 21:31:56,396 INFO [main] org.apache.hadoop.mapred.Task: Task attempt_1624742957627_0001_m_000002_0 is allowed to commit now\n",
      "2021-06-26 21:31:56,423 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_1624742957627_0001_m_000002_0' to hdfs://hadoop:9000/user/hadoop/randomtext\n",
      "2021-06-26 21:31:56,441 INFO [main] org.apache.hadoop.mapred.Task: Task 'attempt_1624742957627_0001_m_000002_0' done.\n",
      "2021-06-26 21:31:56,448 INFO [main] org.apache.hadoop.mapred.Task: Final Counters for attempt_1624742957627_0001_m_000002_0: Counters: 28\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=234786\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=120\n",
      "\t\tHDFS: Number of bytes written=52589092\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1\n",
      "\t\tMap output records=80017\n",
      "\t\tInput split bytes=120\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=181\n",
      "\t\tCPU time spent (ms)=2100\n",
      "\t\tPhysical memory (bytes) snapshot=187654144\n",
      "\t\tVirtual memory (bytes) snapshot=1945567232\n",
      "\t\tTotal committed heap usage (bytes)=87031808\n",
      "\t\tPeak Map Physical memory (bytes)=187654144\n",
      "\t\tPeak Map Virtual memory (bytes)=1945567232\n",
      "\torg.apache.hadoop.examples.RandomTextWriter$Counters\n",
      "\t\tBYTES_WRITTEN=52429058\n",
      "\t\tRECORDS_WRITTEN=80017\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=52589092\n",
      "2021-06-26 21:31:56,449 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping MapTask metrics system...\n",
      "2021-06-26 21:31:56,449 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system stopped.\n",
      "2021-06-26 21:31:56,450 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MapTask metrics system shutdown complete.\n",
      "\n",
      "End of LogType:syslog\n",
      "***********************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000001 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:directory.info\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:2336\n",
      "LogContents:\n",
      "ls -l:\n",
      "total 36\n",
      "-rw-r--r-- 1 hadoop hadoop  100 Jun 26 21:31 container_tokens\n",
      "-rwx------ 1 hadoop hadoop  733 Jun 26 21:31 default_container_executor.sh\n",
      "-rwx------ 1 hadoop hadoop  678 Jun 26 21:31 default_container_executor_session.sh\n",
      "lrwxrwxrwx 1 hadoop hadoop  109 Jun 26 21:31 job.jar -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/11/job.jar\n",
      "lrwxrwxrwx 1 hadoop hadoop  109 Jun 26 21:31 job.xml -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/13/job.xml\n",
      "drwxrwxr-x 2 hadoop hadoop 4096 Jun 26 21:31 jobSubmitDir\n",
      "-rwx------ 1 hadoop hadoop 5130 Jun 26 21:31 launch_container.sh\n",
      "drwx--x--- 2 hadoop hadoop 4096 Jun 26 21:31 tmp\n",
      "find -L . -maxdepth 5 -ls:\n",
      "  1409741      4 drwx--x---   4 hadoop   hadoop       4096 Jun 26 21:31 .\n",
      "  1409751      4 drwxrwxr-x   2 hadoop   hadoop       4096 Jun 26 21:31 ./jobSubmitDir\n",
      "  1381308      4 -r-x------   1 hadoop   hadoop         20 Jun 26 21:31 ./jobSubmitDir/job.splitmetainfo\n",
      "  1381311      4 -r-x------   1 hadoop   hadoop        367 Jun 26 21:31 ./jobSubmitDir/job.split\n",
      "  1381313    196 -r-x------   1 hadoop   hadoop     200592 Jun 26 21:31 ./job.xml\n",
      "  1381325      4 -rwx------   1 hadoop   hadoop        733 Jun 26 21:31 ./default_container_executor.sh\n",
      "  1409750      4 drwx--x---   2 hadoop   hadoop       4096 Jun 26 21:31 ./tmp\n",
      "  1381319      4 -rw-r--r--   1 hadoop   hadoop        100 Jun 26 21:31 ./container_tokens\n",
      "  1381324      4 -rw-r--r--   1 hadoop   hadoop         16 Jun 26 21:31 ./.default_container_executor_session.sh.crc\n",
      "  1381320      4 -rw-r--r--   1 hadoop   hadoop         12 Jun 26 21:31 ./.container_tokens.crc\n",
      "  1381321      8 -rwx------   1 hadoop   hadoop       5130 Jun 26 21:31 ./launch_container.sh\n",
      "  1381322      4 -rw-r--r--   1 hadoop   hadoop         52 Jun 26 21:31 ./.launch_container.sh.crc\n",
      "  1381326      4 -rw-r--r--   1 hadoop   hadoop         16 Jun 26 21:31 ./.default_container_executor.sh.crc\n",
      "  1409172      4 drwx------   2 hadoop   hadoop       4096 Jun 26 21:31 ./job.jar\n",
      "  1381310    312 -r-x------   1 hadoop   hadoop     316483 Jun 26 21:31 ./job.jar/job.jar\n",
      "  1381323      4 -rwx------   1 hadoop   hadoop        678 Jun 26 21:31 ./default_container_executor_session.sh\n",
      "broken symlinks(find -L . -maxdepth 5 -type l -ls):\n",
      "\n",
      "End of LogType:directory.info\n",
      "*******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000001 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:launch_container.sh\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:5130\n",
      "LogContents:\n",
      "#!/bin/bash\n",
      "\n",
      "set -o pipefail -e\n",
      "export PRELAUNCH_OUT=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/prelaunch.out\"\n",
      "exec >\"${PRELAUNCH_OUT}\"\n",
      "export PRELAUNCH_ERR=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/prelaunch.err\"\n",
      "exec 2>\"${PRELAUNCH_ERR}\"\n",
      "echo \"Setting up env variables\"\n",
      "export JAVA_HOME=${JAVA_HOME:-\"/usr/lib/jvm/java-1.8.0-openjdk-amd64\"}\n",
      "export HADOOP_COMMON_HOME=${HADOOP_COMMON_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_HDFS_HOME=${HADOOP_HDFS_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-\"/opt/hadoop/etc/hadoop\"}\n",
      "export HADOOP_YARN_HOME=${HADOOP_YARN_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export HADOOP_HOME=${HADOOP_HOME:-\"/opt/hadoop-3.2.2\"}\n",
      "export PATH=${PATH:-\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\"}\n",
      "export HADOOP_TOKEN_FILE_LOCATION=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000001/container_tokens\"\n",
      "export CONTAINER_ID=\"container_1624742957627_0001_01_000001\"\n",
      "export NM_PORT=\"40733\"\n",
      "export NM_HOST=\"hadoop3\"\n",
      "export NM_HTTP_PORT=\"8042\"\n",
      "export LOCAL_DIRS=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001\"\n",
      "export LOCAL_USER_DIRS=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/\"\n",
      "export LOG_DIRS=\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001\"\n",
      "export USER=\"hadoop\"\n",
      "export LOGNAME=\"hadoop\"\n",
      "export HOME=\"/home/\"\n",
      "export PWD=\"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000001\"\n",
      "export LOCALIZATION_COUNTERS=\"519062,0,4,0,364\"\n",
      "export JVM_PID=\"$$\"\n",
      "export MALLOC_ARENA_MAX=\"4\"\n",
      "export NM_AUX_SERVICE_mapreduce_shuffle=\"AAA0+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"\n",
      "export APPLICATION_WEB_PROXY_BASE=\"/proxy/application_1624742957627_0001\"\n",
      "export SHELL=\"/bin/bash\"\n",
      "export CLASSPATH=\"$PWD:$HADOOP_CONF_DIR:$HADOOP_COMMON_HOME/share/hadoop/common/*:$HADOOP_COMMON_HOME/share/hadoop/common/lib/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/*:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*:$HADOOP_YARN_HOME/share/hadoop/yarn/*:$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*:/opt/hadoop/share/hadoop/mapreduce/*:/opt/hadoop/share/hadoop/mapreduce/lib/*:job.jar/*:job.jar/classes/:job.jar/lib/*:$PWD/*\"\n",
      "export APP_SUBMIT_TIME_ENV=\"1624743105619\"\n",
      "export LD_LIBRARY_PATH=\"$PWD:$HADOOP_COMMON_HOME/lib/native\"\n",
      "echo \"Setting up job resources\"\n",
      "mkdir -p jobSubmitDir\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/10/job.splitmetainfo\" \"jobSubmitDir/job.splitmetainfo\"\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/11/job.jar\" \"job.jar\"\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/13/job.xml\" \"job.xml\"\n",
      "mkdir -p jobSubmitDir\n",
      "ln -sf -- \"/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/filecache/12/job.split\" \"jobSubmitDir/job.split\"\n",
      "echo \"Copying debugging information\"\n",
      "# Creating copy of launch script\n",
      "cp \"launch_container.sh\" \"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/launch_container.sh\"\n",
      "chmod 640 \"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/launch_container.sh\"\n",
      "# Determining directory contents\n",
      "echo \"ls -l:\" 1>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/directory.info\"\n",
      "ls -l 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/directory.info\"\n",
      "echo \"find -L . -maxdepth 5 -ls:\" 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/directory.info\"\n",
      "find -L . -maxdepth 5 -ls 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/directory.info\"\n",
      "echo \"broken symlinks(find -L . -maxdepth 5 -type l -ls):\" 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/directory.info\"\n",
      "find -L . -maxdepth 5 -type l -ls 1>>\"/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/directory.info\"\n",
      "echo \"Launching container\"\n",
      "exec /bin/bash -c \"$JAVA_HOME/bin/java -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1>/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/stdout 2>/opt/hadoop-3.2.2/logs/userlogs/application_1624742957627_0001/container_1624742957627_0001_01_000001/stderr \"\n",
      "\n",
      "End of LogType:launch_container.sh\n",
      "************************************************************************************\n",
      "\n",
      "\n",
      "End of LogType:prelaunch.err\n",
      "******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000001 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:prelaunch.out\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:100\n",
      "LogContents:\n",
      "Setting up env variables\n",
      "Setting up job resources\n",
      "Copying debugging information\n",
      "Launching container\n",
      "\n",
      "End of LogType:prelaunch.out\n",
      "******************************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000001 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:stderr\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:1722\n",
      "LogContents:\n",
      "Jun 26, 2021 9:31:50 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\n",
      "INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class\n",
      "Jun 26, 2021 9:31:50 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\n",
      "INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\n",
      "Jun 26, 2021 9:31:50 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\n",
      "INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class\n",
      "Jun 26, 2021 9:31:50 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\n",
      "INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\n",
      "Jun 26, 2021 9:31:50 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\n",
      "INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\n",
      "Jun 26, 2021 9:31:50 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\n",
      "INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\n",
      "Jun 26, 2021 9:31:50 PM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\n",
      "INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope \"PerRequest\"\n",
      "log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapreduce.v2.app.MRAppMaster).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
      "\n",
      "End of LogType:stderr\n",
      "***********************************************************************\n",
      "\n",
      "\n",
      "End of LogType:stdout\n",
      "***********************************************************************\n",
      "\n",
      "Container: container_1624742957627_0001_01_000001 on hadoop3_40733\n",
      "LogAggregationType: AGGREGATED\n",
      "==================================================================\n",
      "LogType:syslog\n",
      "LogLastModifiedTime:Sat Jun 26 21:32:05 +0000 2021\n",
      "LogLength:61911\n",
      "LogContents:\n",
      "2021-06-26 21:31:48,303 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1624742957627_0001_000001\n",
      "2021-06-26 21:31:48,393 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: \n",
      "/************************************************************\n",
      "[system properties]\n",
      "os.name: Linux\n",
      "os.version: 5.4.0-77-generic\n",
      "java.home: /usr/lib/jvm/java-8-openjdk-amd64/jre\n",
      "java.runtime.version: 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10\n",
      "java.vendor: Private Build\n",
      "java.version: 1.8.0_292\n",
      "java.vm.name: OpenJDK 64-Bit Server VM\n",
      "java.class.path: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000001:/opt/hadoop/etc/hadoop:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-kms-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-nfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/hadoop-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-compress-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/opt/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:job.jar/job.jar:job.jar/classes/:job.jar/lib/*:/tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000001/job.jar\n",
      "java.io.tmpdir: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000001/tmp\n",
      "user.dir: /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000001\n",
      "user.name: hadoop\n",
      "************************************************************/\n",
      "2021-06-26 21:31:48,430 INFO [main] org.apache.hadoop.security.SecurityUtil: Updating Configuration\n",
      "2021-06-26 21:31:48,511 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens: [Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: 1 cluster_timestamp: 1624742957627 } attemptId: 1 } keyId: 1705627045)]\n",
      "2021-06-26 21:31:48,538 INFO [main] org.apache.hadoop.conf.Configuration: resource-types.xml not found\n",
      "2021-06-26 21:31:48,538 INFO [main] org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2021-06-26 21:31:48,549 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.\n",
      "2021-06-26 21:31:48,552 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null\n",
      "2021-06-26 21:31:48,577 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2021-06-26 21:31:48,577 INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2021-06-26 21:31:48,911 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "2021-06-26 21:31:49,033 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler\n",
      "2021-06-26 21:31:49,033 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher\n",
      "2021-06-26 21:31:49,034 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher\n",
      "2021-06-26 21:31:49,035 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher\n",
      "2021-06-26 21:31:49,035 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler\n",
      "2021-06-26 21:31:49,038 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.speculate.Speculator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$SpeculatorEventDispatcher\n",
      "2021-06-26 21:31:49,039 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.rm.ContainerAllocator$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter\n",
      "2021-06-26 21:31:49,039 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher$EventType for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerLauncherRouter\n",
      "2021-06-26 21:31:49,060 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://hadoop:9000]\n",
      "2021-06-26 21:31:49,071 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://hadoop:9000]\n",
      "2021-06-26 21:31:49,082 INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://hadoop:9000]\n",
      "2021-06-26 21:31:49,100 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Perms after creating 488, Expected: 504\n",
      "2021-06-26 21:31:49,100 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Explicitly setting permissions to : 504, rwxrwx---\n",
      "2021-06-26 21:31:49,108 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled\n",
      "2021-06-26 21:31:49,138 INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler\n",
      "2021-06-26 21:31:49,287 INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2021-06-26 21:31:49,348 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2021-06-26 21:31:49,348 INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started\n",
      "2021-06-26 21:31:49,354 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for job_1624742957627_0001 to jobTokenSecretManager\n",
      "2021-06-26 21:31:49,444 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing job_1624742957627_0001 because: not enabled;\n",
      "2021-06-26 21:31:49,463 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job job_1624742957627_0001 = 3. Number of splits = 3\n",
      "2021-06-26 21:31:49,463 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job job_1624742957627_0001 = 0\n",
      "2021-06-26 21:31:49,463 INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1624742957627_0001Job Transitioned from NEW to INITED\n",
      "2021-06-26 21:31:49,464 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job job_1624742957627_0001.\n",
      "2021-06-26 21:31:49,491 INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\n",
      "2021-06-26 21:31:49,499 INFO [Socket Reader #1 for port 0] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0\n",
      "2021-06-26 21:31:49,632 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server\n",
      "2021-06-26 21:31:49,632 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting\n",
      "2021-06-26 21:31:49,632 INFO [IPC Server listener on 0] org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting\n",
      "2021-06-26 21:31:49,633 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at hadoop3/172.17.0.6:43017\n",
      "2021-06-26 21:31:49,658 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.util.log: Logging initialized @2024ms to org.eclipse.jetty.util.log.Slf4jLog\n",
      "2021-06-26 21:31:49,739 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\n",
      "2021-06-26 21:31:49,742 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined\n",
      "2021-06-26 21:31:49,747 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\n",
      "2021-06-26 21:31:49,769 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce\n",
      "2021-06-26 21:31:49,769 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static\n",
      "2021-06-26 21:31:49,771 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.http.HttpServer2: adding path spec: /mapreduce/*\n",
      "2021-06-26 21:31:49,771 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*\n",
      "2021-06-26 21:31:50,103 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules\n",
      "2021-06-26 21:31:50,104 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.http.HttpServer2: Jetty bound to port 34605\n",
      "2021-06-26 21:31:50,105 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10\n",
      "2021-06-26 21:31:50,130 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0\n",
      "2021-06-26 21:31:50,130 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.server.session: No SessionScavenger set, using defaults\n",
      "2021-06-26 21:31:50,131 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.server.session: node0 Scavenging every 660000ms\n",
      "2021-06-26 21:31:50,138 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5e268ce6{static,/static,jar:file:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar!/webapps/static,AVAILABLE}\n",
      "2021-06-26 21:31:50,148 WARN [Listener at 0.0.0.0/43017] org.eclipse.jetty.webapp.WebInfConfiguration: Can't generate resourceBase as part of webapp tmp dir name: java.lang.NullPointerException\n",
      "2021-06-26 21:31:50,236 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules\n",
      "2021-06-26 21:31:50,730 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@10b687f2{mapreduce,/,file:///tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/appcache/application_1624742957627_0001/container_1624742957627_0001_01_000001/tmp/jetty-0_0_0_0-34605-_-any-1521903816084486992.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar!/webapps/mapreduce}\n",
      "2021-06-26 21:31:50,736 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@42f9c19a{HTTP/1.1,[http/1.1]}{0.0.0.0:34605}\n",
      "2021-06-26 21:31:50,736 INFO [Listener at 0.0.0.0/43017] org.eclipse.jetty.server.Server: Started @3102ms\n",
      "2021-06-26 21:31:50,736 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.yarn.webapp.WebApps: Web app mapreduce started at 34605\n",
      "2021-06-26 21:31:50,738 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: JOB_CREATE job_1624742957627_0001\n",
      "2021-06-26 21:31:50,740 INFO [Listener at 0.0.0.0/43017] org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 3000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\n",
      "2021-06-26 21:31:50,740 INFO [Socket Reader #1 for port 0] org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 0\n",
      "2021-06-26 21:31:50,743 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: IPC Server Responder: starting\n",
      "2021-06-26 21:31:50,743 INFO [IPC Server listener on 0] org.apache.hadoop.ipc.Server: IPC Server listener on 0: starting\n",
      "2021-06-26 21:31:50,783 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true\n",
      "2021-06-26 21:31:50,783 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3\n",
      "2021-06-26 21:31:50,783 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33\n",
      "2021-06-26 21:31:50,785 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: 0% of the mappers will be scheduled using OPPORTUNISTIC containers\n",
      "2021-06-26 21:31:50,809 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8030\n",
      "2021-06-26 21:31:50,883 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: maxContainerCapability: <memory:1536, vCores:4>\n",
      "2021-06-26 21:31:50,883 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: queue: default\n",
      "2021-06-26 21:31:50,887 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500\n",
      "2021-06-26 21:31:50,887 INFO [Listener at 0.0.0.0/42871] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: The thread pool initial size is 10\n",
      "2021-06-26 21:31:50,895 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1624742957627_0001Job Transitioned from INITED to SETUP\n",
      "2021-06-26 21:31:50,896 INFO [CommitterEvent Processor #0] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_SETUP\n",
      "2021-06-26 21:31:50,905 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1624742957627_0001Job Transitioned from SETUP to RUNNING\n",
      "2021-06-26 21:31:50,927 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Resource capability of task type MAP is set to <memory:256, vCores:1>\n",
      "2021-06-26 21:31:50,930 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000000 Task Transitioned from NEW to SCHEDULED\n",
      "2021-06-26 21:31:50,930 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000001 Task Transitioned from NEW to SCHEDULED\n",
      "2021-06-26 21:31:50,930 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000002 Task Transitioned from NEW to SCHEDULED\n",
      "2021-06-26 21:31:50,932 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000000_0 TaskAttempt Transitioned from NEW to UNASSIGNED\n",
      "2021-06-26 21:31:50,932 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000001_0 TaskAttempt Transitioned from NEW to UNASSIGNED\n",
      "2021-06-26 21:31:50,932 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000002_0 TaskAttempt Transitioned from NEW to UNASSIGNED\n",
      "2021-06-26 21:31:50,933 INFO [Thread-58] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: mapResourceRequest:<memory:256, vCores:1>\n",
      "2021-06-26 21:31:50,981 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1624742957627_0001, File: hdfs://hadoop:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0001/job_1624742957627_0001_1.jhist\n",
      "2021-06-26 21:31:51,885 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:3 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0\n",
      "2021-06-26 21:31:51,931 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1624742957627_0001: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:4096, vCores:23> knownNMs=3\n",
      "2021-06-26 21:31:52,968 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 3\n",
      "2021-06-26 21:31:52,970 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1624742957627_0001_01_000002 to attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:52,972 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1624742957627_0001_01_000003 to attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:52,972 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1624742957627_0001_01_000004 to attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:52,972 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:3 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:3 ContRel:0 HostLocal:0 RackLocal:0\n",
      "2021-06-26 21:31:53,030 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-jar file on the remote FS is hdfs://hadoop:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0001/job.jar\n",
      "2021-06-26 21:31:53,033 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0001/job.xml\n",
      "2021-06-26 21:31:53,035 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container\n",
      "2021-06-26 21:31:53,035 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Size of containertokens_dob is 1\n",
      "2021-06-26 21:31:53,035 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Putting shuffle token in serviceData\n",
      "2021-06-26 21:31:53,057 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapred.JobConf: Task java-opts do not specify heap size. Setting task attempt jvm max heap size to -Xmx205m\n",
      "2021-06-26 21:31:53,060 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED\n",
      "2021-06-26 21:31:53,063 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapred.JobConf: Task java-opts do not specify heap size. Setting task attempt jvm max heap size to -Xmx205m\n",
      "2021-06-26 21:31:53,064 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED\n",
      "2021-06-26 21:31:53,065 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapred.JobConf: Task java-opts do not specify heap size. Setting task attempt jvm max heap size to -Xmx205m\n",
      "2021-06-26 21:31:53,065 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED\n",
      "2021-06-26 21:31:53,066 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1624742957627_0001_01_000002 taskAttempt attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:53,066 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1624742957627_0001_01_000003 taskAttempt attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:53,067 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_1624742957627_0001_01_000004 taskAttempt attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:53,069 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:53,069 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:53,069 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:53,139 INFO [ContainerLauncher #2] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1624742957627_0001_m_000002_0 : 13562\n",
      "2021-06-26 21:31:53,141 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1624742957627_0001_m_000002_0] using containerId: [container_1624742957627_0001_01_000004 on NM: [hadoop3:40733]\n",
      "2021-06-26 21:31:53,144 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000002_0 TaskAttempt Transitioned from ASSIGNED to RUNNING\n",
      "2021-06-26 21:31:53,145 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: ATTEMPT_START task_1624742957627_0001_m_000002\n",
      "2021-06-26 21:31:53,145 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000002 Task Transitioned from SCHEDULED to RUNNING\n",
      "2021-06-26 21:31:53,381 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1624742957627_0001_m_000000_0 : 13562\n",
      "2021-06-26 21:31:53,381 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1624742957627_0001_m_000000_0] using containerId: [container_1624742957627_0001_01_000002 on NM: [hadoop1:46409]\n",
      "2021-06-26 21:31:53,382 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING\n",
      "2021-06-26 21:31:53,382 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: ATTEMPT_START task_1624742957627_0001_m_000000\n",
      "2021-06-26 21:31:53,382 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000000 Task Transitioned from SCHEDULED to RUNNING\n",
      "2021-06-26 21:31:53,451 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1624742957627_0001_m_000001_0 : 13562\n",
      "2021-06-26 21:31:53,451 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1624742957627_0001_m_000001_0] using containerId: [container_1624742957627_0001_01_000003 on NM: [hadoop2:46223]\n",
      "2021-06-26 21:31:53,452 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000001_0 TaskAttempt Transitioned from ASSIGNED to RUNNING\n",
      "2021-06-26 21:31:53,452 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: ATTEMPT_START task_1624742957627_0001_m_000001\n",
      "2021-06-26 21:31:53,452 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000001 Task Transitioned from SCHEDULED to RUNNING\n",
      "2021-06-26 21:31:53,975 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1624742957627_0001: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:3328, vCores:20> knownNMs=3\n",
      "2021-06-26 21:31:54,384 INFO [Socket Reader #1 for port 0] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1624742957627_0001 (auth:SIMPLE) from 172.17.0.6:42520\n",
      "2021-06-26 21:31:54,403 INFO [IPC Server handler 0 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1624742957627_0001_m_000004 asked for a task\n",
      "2021-06-26 21:31:54,404 INFO [IPC Server handler 0 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1624742957627_0001_m_000004 given task: attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:55,605 INFO [Socket Reader #1 for port 0] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1624742957627_0001 (auth:SIMPLE) from 172.17.0.4:34890\n",
      "2021-06-26 21:31:55,623 INFO [IPC Server handler 3 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1624742957627_0001_m_000002 asked for a task\n",
      "2021-06-26 21:31:55,623 INFO [IPC Server handler 3 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1624742957627_0001_m_000002 given task: attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:55,781 INFO [Socket Reader #1 for port 0] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1624742957627_0001 (auth:SIMPLE) from 172.17.0.5:40322\n",
      "2021-06-26 21:31:55,793 INFO [IPC Server handler 0 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1624742957627_0001_m_000003 asked for a task\n",
      "2021-06-26 21:31:55,793 INFO [IPC Server handler 0 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1624742957627_0001_m_000003 given task: attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:56,353 INFO [IPC Server handler 3 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1624742957627_0001_m_000002_0 is : 0.0\n",
      "2021-06-26 21:31:56,393 INFO [IPC Server handler 4 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:56,394 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000002_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING\n",
      "2021-06-26 21:31:56,394 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1624742957627_0001_m_000002_0 given a go for committing the task output.\n",
      "2021-06-26 21:31:56,395 INFO [IPC Server handler 5 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:56,396 INFO [IPC Server handler 5 on default port 42871] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1624742957627_0001_m_000002_0:true\n",
      "2021-06-26 21:31:56,433 INFO [IPC Server handler 6 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1624742957627_0001_m_000002_0 is : 1.0\n",
      "2021-06-26 21:31:56,440 INFO [IPC Server handler 2 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgment from attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:56,444 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000002_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_FINISHING_CONTAINER\n",
      "2021-06-26 21:31:56,459 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:56,465 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000002 Task Transitioned from RUNNING to SUCCEEDED\n",
      "2021-06-26 21:31:56,477 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 1\n",
      "2021-06-26 21:31:56,989 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:3 AssignedReds:0 CompletedMaps:1 CompletedReds:0 ContAlloc:3 ContRel:0 HostLocal:0 RackLocal:0\n",
      "2021-06-26 21:31:57,006 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1624742957627_0001_01_000004\n",
      "2021-06-26 21:31:57,008 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1624742957627_0001_m_000002_0: \n",
      "2021-06-26 21:31:57,008 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:2 AssignedReds:0 CompletedMaps:1 CompletedReds:0 ContAlloc:3 ContRel:0 HostLocal:0 RackLocal:0\n",
      "2021-06-26 21:31:57,008 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000002_0 TaskAttempt Transitioned from SUCCESS_FINISHING_CONTAINER to SUCCEEDED\n",
      "2021-06-26 21:31:57,014 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_COMPLETED for container container_1624742957627_0001_01_000004 taskAttempt attempt_1624742957627_0001_m_000002_0\n",
      "2021-06-26 21:31:57,640 INFO [IPC Server handler 1 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1624742957627_0001_m_000000_0 is : 0.0\n",
      "2021-06-26 21:31:57,681 INFO [IPC Server handler 8 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:57,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000000_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING\n",
      "2021-06-26 21:31:57,682 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1624742957627_0001_m_000000_0 given a go for committing the task output.\n",
      "2021-06-26 21:31:57,683 INFO [IPC Server handler 7 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:57,684 INFO [IPC Server handler 7 on default port 42871] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1624742957627_0001_m_000000_0:true\n",
      "2021-06-26 21:31:57,717 INFO [IPC Server handler 10 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1624742957627_0001_m_000000_0 is : 1.0\n",
      "2021-06-26 21:31:57,720 INFO [IPC Server handler 9 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgment from attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:57,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000000_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_FINISHING_CONTAINER\n",
      "2021-06-26 21:31:57,721 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:57,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000000 Task Transitioned from RUNNING to SUCCEEDED\n",
      "2021-06-26 21:31:57,722 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 2\n",
      "2021-06-26 21:31:57,761 INFO [IPC Server handler 16 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1624742957627_0001_m_000001_0 is : 0.0\n",
      "2021-06-26 21:31:57,773 INFO [DefaultSpeculator background processing] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_1624742957627_0001_m_000001\n",
      "2021-06-26 21:31:57,773 INFO [DefaultSpeculator background processing] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: We launched 1 speculations.  Sleeping 15000 milliseconds.\n",
      "2021-06-26 21:31:57,773 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Scheduling a redundant attempt for task task_1624742957627_0001_m_000001\n",
      "2021-06-26 21:31:57,774 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000001_1 TaskAttempt Transitioned from NEW to UNASSIGNED\n",
      "2021-06-26 21:31:57,786 INFO [IPC Server handler 0 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:57,787 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000001_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING\n",
      "2021-06-26 21:31:57,787 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1624742957627_0001_m_000001_0 given a go for committing the task output.\n",
      "2021-06-26 21:31:57,788 INFO [IPC Server handler 3 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:57,788 INFO [IPC Server handler 3 on default port 42871] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1624742957627_0001_m_000001_0:true\n",
      "2021-06-26 21:31:57,808 INFO [IPC Server handler 4 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1624742957627_0001_m_000001_0 is : 1.0\n",
      "2021-06-26 21:31:57,811 INFO [IPC Server handler 5 on default port 42871] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgment from attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:57,811 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000001_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_FINISHING_CONTAINER\n",
      "2021-06-26 21:31:57,812 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:57,812 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Issuing kill to other attempt attempt_1624742957627_0001_m_000001_1\n",
      "2021-06-26 21:31:57,812 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1624742957627_0001_m_000001 Task Transitioned from RUNNING to SUCCEEDED\n",
      "2021-06-26 21:31:57,813 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3\n",
      "2021-06-26 21:31:57,813 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1624742957627_0001Job Transitioned from RUNNING to COMMITTING\n",
      "2021-06-26 21:31:57,815 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000001_1 TaskAttempt Transitioned from UNASSIGNED to KILLED\n",
      "2021-06-26 21:31:57,815 INFO [Thread-58] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE\n",
      "2021-06-26 21:31:57,815 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_COMMIT\n",
      "2021-06-26 21:31:57,868 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent \n",
      "2021-06-26 21:31:57,868 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1624742957627_0001Job Transitioned from COMMITTING to SUCCEEDED\n",
      "2021-06-26 21:31:57,869 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Job finished cleanly, recording last MRAppMaster retry\n",
      "2021-06-26 21:31:57,869 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true\n",
      "2021-06-26 21:31:57,869 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true\n",
      "2021-06-26 21:31:57,869 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true\n",
      "2021-06-26 21:31:57,869 INFO [Thread-74] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true\n",
      "2021-06-26 21:31:57,869 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services\n",
      "2021-06-26 21:31:57,869 INFO [Thread-74] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0\n",
      "2021-06-26 21:31:57,931 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://hadoop:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0001/job_1624742957627_0001_1.jhist to hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001-1624743105619-hadoop-random%2Dtext%2Dwriter-1624743117865-3-0-SUCCEEDED-default-1624743110890.jhist_tmp\n",
      "2021-06-26 21:31:58,008 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:2 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:3 ContRel:0 HostLocal:0 RackLocal:0\n",
      "2021-06-26 21:31:58,017 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1624742957627_0001: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:3584, vCores:21> knownNMs=3\n",
      "2021-06-26 21:31:58,023 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied from: hdfs://hadoop:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0001/job_1624742957627_0001_1.jhist to done location: hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001-1624743105619-hadoop-random%2Dtext%2Dwriter-1624743117865-3-0-SUCCEEDED-default-1624743110890.jhist_tmp\n",
      "2021-06-26 21:31:58,025 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Set historyUrl to http://hadoop3:19888/jobhistory/job/job_1624742957627_0001\n",
      "2021-06-26 21:31:58,029 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://hadoop:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0001/job_1624742957627_0001_1_conf.xml to hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001_conf.xml_tmp\n",
      "2021-06-26 21:31:58,098 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied from: hdfs://hadoop:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0001/job_1624742957627_0001_1_conf.xml to done location: hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001_conf.xml_tmp\n",
      "2021-06-26 21:31:58,109 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001.summary_tmp to hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001.summary\n",
      "2021-06-26 21:31:58,116 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001_conf.xml_tmp to hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001_conf.xml\n",
      "2021-06-26 21:31:58,124 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001-1624743105619-hadoop-random%2Dtext%2Dwriter-1624743117865-3-0-SUCCEEDED-default-1624743110890.jhist_tmp to hdfs://hadoop:9000/tmp/hadoop-yarn/staging/history/done_intermediate/hadoop/job_1624742957627_0001-1624743105619-hadoop-random%2Dtext%2Dwriter-1624743117865-3-0-SUCCEEDED-default-1624743110890.jhist\n",
      "2021-06-26 21:31:58,125 INFO [Thread-74] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()\n",
      "2021-06-26 21:31:58,125 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1624742957627_0001_m_000001_0\n",
      "2021-06-26 21:31:58,160 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000001_0 TaskAttempt Transitioned from SUCCESS_FINISHING_CONTAINER to SUCCEEDED\n",
      "2021-06-26 21:31:58,161 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1624742957627_0001_m_000000_0\n",
      "2021-06-26 21:31:58,196 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1624742957627_0001_m_000000_0 TaskAttempt Transitioned from SUCCESS_FINISHING_CONTAINER to SUCCEEDED\n",
      "2021-06-26 21:31:58,197 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Setting job diagnostics to \n",
      "2021-06-26 21:31:58,197 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: History url is http://hadoop3:19888/jobhistory/job/job_1624742957627_0001\n",
      "2021-06-26 21:31:58,212 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Waiting for application to be successfully unregistered.\n",
      "2021-06-26 21:31:59,216 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:2 AssignedReds:0 CompletedMaps:3 CompletedReds:0 ContAlloc:3 ContRel:0 HostLocal:0 RackLocal:0\n",
      "2021-06-26 21:31:59,220 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://hadoop:9000 /tmp/hadoop-yarn/staging/hadoop/.staging/job_1624742957627_0001\n",
      "2021-06-26 21:31:59,230 INFO [Thread-74] org.apache.hadoop.ipc.Server: Stopping server on 42871\n",
      "2021-06-26 21:31:59,233 INFO [IPC Server listener on 0] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 0\n",
      "2021-06-26 21:31:59,233 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder\n",
      "2021-06-26 21:31:59,234 INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted\n",
      "2021-06-26 21:31:59,235 INFO [Ping Checker] org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: TaskAttemptFinishingMonitor thread interrupted\n",
      "2021-06-26 21:32:04,235 INFO [Thread-74] org.apache.hadoop.ipc.Server: Stopping server on 43017\n",
      "2021-06-26 21:32:04,236 INFO [IPC Server listener on 0] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 0\n",
      "2021-06-26 21:32:04,236 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder\n",
      "2021-06-26 21:32:04,244 INFO [Thread-74] org.eclipse.jetty.server.handler.ContextHandler: Stopped o.e.j.w.WebAppContext@10b687f2{mapreduce,/,null,UNAVAILABLE}{jar:file:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar!/webapps/mapreduce}\n",
      "2021-06-26 21:32:04,256 INFO [Thread-74] org.eclipse.jetty.server.AbstractConnector: Stopped ServerConnector@42f9c19a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}\n",
      "2021-06-26 21:32:04,257 INFO [Thread-74] org.eclipse.jetty.server.session: node0 Stopped scavenging\n",
      "2021-06-26 21:32:04,257 INFO [Thread-74] org.eclipse.jetty.server.handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5e268ce6{static,/static,jar:file:/opt/hadoop-3.2.2/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar!/webapps/static,UNAVAILABLE}\n",
      "\n",
      "End of LogType:syslog\n",
      "***********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "APPID=$(yarn application -list -appStates FINISHED 2>/dev/null | tail -1 | awk '{ print $1 }')\n",
    "echo \"Getting logs for $APPID\"\n",
    "yarn logs -applicationId $APPID 2>/dev/null #| head -n 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kill application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "APPID=$(yarn application -list -appStates RUNNING 2>/dev/null | tail -1 | awk '{ print $1 }')\n",
    "echo \"Killing $APPID\"\n",
    "yarn application -kill $APPID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling nodemanager failures\n",
    "\n",
    "- yarn.nm.liveness-monitor.expiry-interval-ms property in yarn-site.xml\n",
    " - set to 10000 (10 seconds) / default is 600000 (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'hadoop1,172.17.0.4' (ECDSA) to the list of known hosts.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# simulate node fault\n",
    "ssh hadoop1 'kill -9 $(cat /tmp/hadoop-hadoop-nodemanager.pid)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://localhost:8088/cluster/nodes\n",
    "- Wait 10 seconds to discover node failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes:3\n",
      "         Node-Id\t     Node-State\tNode-Http-Address\tNumber-of-Running-Containers\n",
      "   hadoop2:46223\t        RUNNING\t     hadoop2:8042\t                           0\n",
      "Detailed Node Information :\n",
      "\tConfigured Resources : <memory:1536, vCores:8>\n",
      "\tAllocated Resources : <memory:0, vCores:0>\n",
      "\tResource Utilization by Node : PMem:10817 MB, VMem:11034 MB, VCores:0.32644904\n",
      "\tResource Utilization by Containers : PMem:0 MB, VMem:0 MB, VCores:0.0\n",
      "\tNode-Labels : \n",
      "   hadoop1:43505\t        RUNNING\t     hadoop1:8042\t                           0\n",
      "Detailed Node Information :\n",
      "\tConfigured Resources : <memory:1536, vCores:8>\n",
      "\tAllocated Resources : <memory:0, vCores:0>\n",
      "\tResource Utilization by Node : PMem:10826 MB, VMem:11043 MB, VCores:0.44955045\n",
      "\tResource Utilization by Containers : PMem:0 MB, VMem:0 MB, VCores:0.0\n",
      "\tNode-Labels : \n",
      "   hadoop3:40733\t        RUNNING\t     hadoop3:8042\t                           0\n",
      "Detailed Node Information :\n",
      "\tConfigured Resources : <memory:1536, vCores:8>\n",
      "\tAllocated Resources : <memory:0, vCores:0>\n",
      "\tResource Utilization by Node : PMem:10848 MB, VMem:11065 MB, VCores:0.58\n",
      "\tResource Utilization by Containers : PMem:0 MB, VMem:0 MB, VCores:0.0\n",
      "\tNode-Labels : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-26 21:42:59,481 INFO client.RMProxy: Connecting to ResourceManager at hadoop/172.17.0.3:8032\n",
      "2021-06-26 21:42:59,642 INFO client.AHSProxy: Connecting to Application History server at hadoop/172.17.0.3:10200\n",
      "2021-06-26 21:42:59,753 INFO conf.Configuration: resource-types.xml not found\n",
      "2021-06-26 21:42:59,754 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "yarn node -list -showDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added 'hadoop1,172.17.0.4' (ECDSA) to the list of known hosts.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Restart nodemanager\n",
    "ssh hadoop1 /opt/hadoop/bin/yarn --daemon start nodemanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
